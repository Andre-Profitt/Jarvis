#!/usr/bin/env python3
"""
Multi-AI Integration Setup for JARVIS
Configures connections to Claude, GPT-4, and Gemini
"""
import os
import json
from pathlib import Path
import logging

logging.basicConfig(level=logging.INFO, format='%(message)s')
logger = logging.getLogger(__name__)

def setup_multi_ai():
    """Setup multi-AI integration"""
    logger.info("ü§ñ Setting up Multi-AI Integration...\n")
    
    # Check for API keys in environment
    api_keys = {
        "ANTHROPIC_API_KEY": os.getenv("ANTHROPIC_API_KEY"),
        "OPENAI_API_KEY": os.getenv("OPENAI_API_KEY"),
        "GOOGLE_API_KEY": os.getenv("GOOGLE_API_KEY"),
    }
    
    # Report status
    available_ais = []
    for key_name, key_value in api_keys.items():
        if key_value:
            ai_name = key_name.split("_")[0]
            available_ais.append(ai_name)
            logger.info(f"‚úÖ {ai_name} API key found")
        else:
            logger.info(f"‚ö†Ô∏è  {key_name} not found in environment")
    
    # Create a minimal working multi-AI integration
    multi_ai_config = {
        "version": "1.0",
        "available_models": [],
        "default_model": "claude" if "ANTHROPIC" in available_ais else "minimal",
        "fallback_chain": []
    }
    
    # Add available models
    if "ANTHROPIC" in available_ais:
        multi_ai_config["available_models"].append({
            "name": "claude",
            "provider": "anthropic",
            "model": "claude-3-opus-20240229",
            "max_tokens": 4096
        })
        multi_ai_config["fallback_chain"].append("claude")
    
    if "OPENAI" in available_ais:
        multi_ai_config["available_models"].append({
            "name": "gpt4",
            "provider": "openai",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4096
        })
        multi_ai_config["fallback_chain"].append("gpt4")
    
    if "GOOGLE" in available_ais:
        multi_ai_config["available_models"].append({
            "name": "gemini",
            "provider": "google",
            "model": "gemini-pro",
            "max_tokens": 4096
        })
        multi_ai_config["fallback_chain"].append("gemini")
    
    # Save configuration
    config_path = Path("config/multi_ai_config.json")
    config_path.parent.mkdir(exist_ok=True)
    
    with open(config_path, 'w') as f:
        json.dump(multi_ai_config, f, indent=2)
    
    logger.info(f"\n‚úÖ Multi-AI configuration saved to {config_path}")
    logger.info(f"üìä Available AI models: {len(multi_ai_config['available_models'])}")
    
    # Create a minimal working integration module
    integration_code = '''"""
Minimal Multi-AI Integration Module
"""
import os
import json
from pathlib import Path

class MultiAIIntegration:
    """Minimal multi-AI integration"""
    
    def __init__(self):
        self.config_path = Path("config/multi_ai_config.json")
        self.config = self._load_config()
        self.available_models = {m["name"]: m for m in self.config.get("available_models", [])}
        
    def _load_config(self):
        """Load configuration"""
        if self.config_path.exists():
            with open(self.config_path) as f:
                return json.load(f)
        return {"available_models": [], "default_model": "minimal"}
    
    def get_available_models(self):
        """Get list of available models"""
        return list(self.available_models.keys())
    
    async def query(self, prompt, model=None):
        """Query an AI model"""
        if not model:
            model = self.config.get("default_model", "minimal")
        
        if model == "minimal" or model not in self.available_models:
            return f"[Minimal response] Received: {prompt[:50]}..."
        
        # In a real implementation, this would call the actual APIs
        return f"[{model} response would go here]"

# Create global instance
multi_ai = MultiAIIntegration()
'''
    
    # Save the integration module
    integration_path = Path("core/updated_multi_ai_integration.py")
    with open(integration_path, 'w') as f:
        f.write(integration_code)
    
    logger.info(f"‚úÖ Created minimal multi-AI integration at {integration_path}")
    
    return multi_ai_config

def test_multi_ai():
    """Test the multi-AI setup"""
    logger.info("\nüß™ Testing Multi-AI Integration...")
    
    try:
        from core.updated_multi_ai_integration import multi_ai
        
        models = multi_ai.get_available_models()
        logger.info(f"‚úÖ Available models: {models}")
        
        # Test query
        import asyncio
        result = asyncio.run(multi_ai.query("Hello, AI!"))
        logger.info(f"‚úÖ Test query result: {result}")
        
        return True
    except Exception as e:
        logger.error(f"‚ùå Test failed: {e}")
        return False

def main():
    """Main setup function"""
    # Setup multi-AI
    config = setup_multi_ai()
    
    # Test it
    if test_multi_ai():
        logger.info("\n‚ú® Multi-AI Integration is ready!")
        logger.info("\nüöÄ Next steps:")
        logger.info("  1. Add API keys to .env file if missing")
        logger.info("  2. Restart JARVIS to load new configuration")
        logger.info("  3. Test with: python3 test_multi_ai.py")
    else:
        logger.info("\n‚ö†Ô∏è  Multi-AI Integration needs configuration")
        logger.info("  Add API keys to your .env file")

if __name__ == "__main__":
    main()
