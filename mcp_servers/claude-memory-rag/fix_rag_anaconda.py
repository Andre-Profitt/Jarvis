#!/usr/bin/env python3
"""
Alternative: Fix RAG for Anaconda without virtual environment
Uses conda-friendly packages and workarounds
"""

import os
import sys
import subprocess
from pathlib import Path
import json

print("üöÄ Fixing Full RAG for Anaconda Environment")
print("=" * 60)


def install_with_conda_pip():
    """Install using conda where possible, pip for others"""
    print("\nüì¶ Installing dependencies with conda/pip mix...")

    # First, try conda for scientific packages
    conda_packages = [
        "numpy",
        "pandas",
        "pytorch",
        "cpuonly",  # CPU-only PyTorch to save space
        "-c",
        "pytorch",  # From PyTorch channel
    ]

    print("üìå Installing PyTorch with conda...")
    subprocess.run(["conda", "install", "-y"] + conda_packages, capture_output=True)

    # Then pip for the rest
    pip_packages = [
        "google-cloud-storage",
        "chromadb",
        "transformers",
        # Skip sentence-transformers for now
        "tqdm",
    ]

    for package in pip_packages:
        print(f"üìå Installing {package}...")
        result = subprocess.run(
            [sys.executable, "-m", "pip", "install", package],
            capture_output=True,
            text=True,
        )
        if result.returncode == 0:
            print(f"   ‚úÖ {package} installed")
        else:
            print(f"   ‚ö†Ô∏è  {package} had issues")


def create_simple_embedder():
    """Create a simple working embedder"""
    print("\nüîß Creating optimized embedder...")

    embedder_code = '''#!/usr/bin/env python3
"""
Optimized embedder for Anaconda environments
Works without sentence-transformers
"""

import hashlib
import numpy as np
from typing import List, Union
import torch

class OptimizedEmbedder:
    """Embedder using basic transformers instead of sentence-transformers"""
    
    def __init__(self, model_name="bert-base-uncased"):
        self.device = "cpu"
        self.embedding_dim = 384
        
        try:
            from transformers import AutoTokenizer, AutoModel
            self.tokenizer = AutoTokenizer.from_pretrained(model_name)
            self.model = AutoModel.from_pretrained(model_name)
            self.model.eval()
            self.use_transformer = True
            print("‚úÖ Using transformer embeddings")
        except:
            self.use_transformer = False
            print("‚ö†Ô∏è Using hash embeddings")
    
    def encode(self, texts: Union[str, List[str]], batch_size=32, show_progress_bar=False):
        """Encode texts to embeddings"""
        if isinstance(texts, str):
            texts = [texts]
        
        if self.use_transformer:
            return self._transformer_encode(texts)
        else:
            return self._hash_encode(texts)
    
    def _transformer_encode(self, texts: List[str]) -> np.ndarray:
        """Use transformer model for embeddings"""
        embeddings = []
        
        with torch.no_grad():
            for text in texts:
                # Tokenize
                inputs = self.tokenizer(text, padding=True, truncation=True, 
                                      max_length=512, return_tensors="pt")
                
                # Get embeddings
                outputs = self.model(**inputs)
                
                # Use CLS token embedding
                embedding = outputs.last_hidden_state[0, 0].numpy()
                
                # Resize to expected dimension
                if len(embedding) != self.embedding_dim:
                    # Simple projection
                    embedding = embedding[:self.embedding_dim]
                    if len(embedding) < self.embedding_dim:
                        embedding = np.pad(embedding, (0, self.embedding_dim - len(embedding)))
                
                embeddings.append(embedding)
        
        return np.array(embeddings)
    
    def _hash_encode(self, texts: List[str]) -> np.ndarray:
        """Fallback hash-based encoding"""
        embeddings = []
        
        for text in texts:
            words = text.lower().split()[:100]
            embedding = np.zeros(self.embedding_dim)
            
            for i, word in enumerate(words):
                hash_val = int(hashlib.md5(word.encode()).hexdigest(), 16)
                idx = hash_val % self.embedding_dim
                embedding[idx] += 1.0 / (i + 1)
            
            # Normalize
            norm = np.linalg.norm(embedding)
            if norm > 0:
                embedding = embedding / norm
            
            embeddings.append(embedding)
        
        return np.array(embeddings)

# Make it compatible with sentence_transformers API
class SentenceTransformer(OptimizedEmbedder):
    """Compatibility wrapper"""
    pass
'''

    # Save embedder
    embedder_path = Path(__file__).parent / "optimized_embedder.py"
    embedder_path.write_text(embedder_code)
    print("‚úÖ Optimized embedder created")


def patch_server():
    """Patch the server to use our embedder"""
    print("\nüìù Patching server for Anaconda compatibility...")

    server_path = Path(__file__).parent / "server.py"

    if server_path.exists():
        server_code = server_path.read_text()

        # Replace sentence_transformers import
        new_import = """# Anaconda-compatible imports
try:
    from sentence_transformers import SentenceTransformer
except ImportError:
    # Use our optimized embedder
    import sys
    from pathlib import Path
    sys.path.insert(0, str(Path(__file__).parent))
    from optimized_embedder import SentenceTransformer
"""

        # Replace the import line
        import_line = "from sentence_transformers import SentenceTransformer"
        if import_line in server_code:
            server_code = server_code.replace(import_line, new_import)

            # Save patched server
            backup_path = server_path.with_suffix(".py.backup")
            server_path.rename(backup_path)
            server_path.write_text(server_code)
            print("‚úÖ Server patched (backup created)")


def quick_test():
    """Quick test of the setup"""
    print("\nüß™ Quick test...")

    test_code = """
import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent))

try:
    from optimized_embedder import SentenceTransformer
    
    # Test embedder
    embedder = SentenceTransformer()
    test_text = "Testing the embedder"
    embedding = embedder.encode(test_text)
    
    print(f"‚úÖ Embedder works! Shape: {embedding.shape}")
    
    # Test imports
    import chromadb
    print("‚úÖ ChromaDB imports")
    
    from google.cloud import storage
    print("‚úÖ Google Cloud Storage imports")
    
    print("\\n‚úÖ Basic dependencies working!")
    
except Exception as e:
    print(f"‚ùå Error: {e}")
"""

    subprocess.run([sys.executable, "-c", test_code])


def update_config():
    """Update Claude config"""
    print("\nüîß Updating Claude Desktop config...")

    config_path = (
        Path.home() / "Library/Application Support/Claude/claude_desktop_config.json"
    )

    if config_path.exists():
        with open(config_path, "r") as f:
            config = json.load(f)
    else:
        config = {"mcpServers": {}}

    # Update with current Python
    config["mcpServers"]["claude-memory-rag"] = {
        "command": sys.executable,  # Use current Python
        "args": [str(Path(__file__).parent / "server.py")],
        "env": {
            "GOOGLE_APPLICATION_CREDENTIALS": str(
                Path.home() / ".gcs/jarvis-credentials.json"
            ),
            "GCS_BUCKET": "jarvis-memory-storage",
            "PYTHONPATH": str(Path(__file__).parent.parent.parent),
        },
    }

    with open(config_path, "w") as f:
        json.dump(config, f, indent=2)

    print("‚úÖ Claude config updated!")


def main():
    print("\nüéØ This will fix RAG to work with your Anaconda setup")

    # Install what we can
    install_with_conda_pip()

    # Create embedder
    create_simple_embedder()

    # Patch server
    patch_server()

    # Test
    quick_test()

    # Update config
    update_config()

    print("\n" + "=" * 60)
    print("üéâ RAG Fixed for Anaconda!")
    print("=" * 60)

    print("\n‚úÖ What we did:")
    print("1. Installed compatible dependencies")
    print("2. Created optimized embedder (no sentence-transformers)")
    print("3. Patched server for compatibility")
    print("4. Updated Claude config")

    print("\nüìù Next steps:")
    print("1. Restart Claude Desktop")
    print("2. Test with: python test_memory.py")
    print("3. Index JARVIS: python index_jarvis.py")

    print("\nüí° This version uses:")
    print("- Optimized embeddings (transformer or hash-based)")
    print("- ChromaDB for vector storage")
    print("- Google Cloud Storage backup")
    print("- Full RAG functionality!")


if __name__ == "__main__":
    main()
